import os, sys, json, errno, shutil, random, pickle
import numpy as np
import pandas as pd
from tqdm import tqdm
from urllib.request import urlretrieve
from socket import error as SocketError
from PIL import Image
import tensorflow as tf
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, Conv2D, Conv2DTranspose, Activation, Flatten, Lambda, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K
from matplotlib import pyplot as plt

try:
    from pycocotools.coco import COCO
    HAS_COCO = True
except Exception:
    HAS_COCO = False

def load_class(cat_name, prefix='train2017', annotation_folder='./annotations', download=False):
    if not HAS_COCO:
        raise RuntimeError("pycocotools not available")
    instances = f"{annotation_folder}/instances_{prefix}.json"
    captions = f"{annotation_folder}/captions_{prefix}.json"
    coco = COCO(instances)
    coco_txt = COCO(captions)
    category_ids = coco.getCatIds([cat_name])
    image_ids = coco.getImgIds(catIds=category_ids)
    os.makedirs('./data/cat', exist_ok=True)
    os.makedirs('./data/cat_ann', exist_ok=True)
    for i in tqdm(image_ids, desc='Downloading images'):
        try:
            image_data = coco.loadImgs(i)[0]
            urlretrieve(image_data['coco_url'], f"./data/cat/{image_data['file_name']}")
        except SocketError as e:
            if e.errno != errno.ECONNRESET:
                raise
            pass
    ann_ids = coco.getAnnIds(catIds=category_ids)
    all_ann = coco.loadAnns(ann_ids)
    rows = []
    for a in tqdm(all_ann, desc='Collecting bboxes'):
        bb = a["bbox"]
        inf = coco.loadImgs(a["image_id"])[0]
        filename = inf["file_name"]
        width, height = inf["width"], inf["height"]
        xmin, ymin = int(bb[0]), int(bb[1])
        xmax = min(int(xmin + bb[2]), width - 1)
        ymax = min(int(ymin + bb[3]), height - 1)
        rows.append([filename, inf["id"], width, height, cat_name, xmin, ymin, xmax, ymax])
    df = pd.DataFrame(rows, columns=["filename","idx","width","height","class","xmin","ymin","xmax","ymax"])
    with open(captions, 'r') as f:
        ann_txt = json.load(f)
    rows_txt = [[a['image_id'], a['caption']] for a in ann_txt['annotations'] if a['image_id'] in set(df.idx)]
    df_txt = pd.DataFrame(rows_txt, columns=["idx","description"])
    df = df[df['filename'].isin(os.listdir('./data/cat'))]
    df.to_csv(f'./data/cat_ann/ann_BB_{prefix}.csv', index=False)
    df_txt = df_txt[df_txt['idx'].isin(df['idx'])]
    df_txt.to_csv(f'./data/cat_ann/ann_description_{prefix}.csv', index=False)
    data_concat = df_txt.merge(df, on='idx')
    data_concat.to_csv(f'./data/cat_ann/ann_description+BB_{prefix}.csv', index=False)
    shutil.make_archive(f'img_{prefix}', 'zip', './data/cat')
    if download:
        pass

def load_class_ids(path):
    with open(path, 'rb') as f:
        return pickle.load(f, encoding='latin1')

def load_embeddings(path):
    with open(path, 'rb') as f:
        E = pickle.load(f, encoding='latin1')
    return np.array(E)

def load_filenames(path):
    with open(path, 'rb') as f:
        return pickle.load(f, encoding='latin1')

def load_bounding_boxes(dataset_dir):
    bb_path = os.path.join(dataset_dir, 'bounding_boxes.txt')
    fp_path = os.path.join(dataset_dir, 'images.txt')
    df_bb = pd.read_csv(bb_path, delim_whitespace=True, header=None).astype(int)
    df_fn = pd.read_csv(fp_path, delim_whitespace=True, header=None)
    files = df_fn[1].tolist()
    d = {}
    for i in range(len(files)):
        bb = df_bb.iloc[i][1:].tolist()
        d[files[i][:-4]] = bb
    return d

def get_img(img_path, bbox, image_size):
    img = Image.open(img_path).convert('RGB')
    w, h = img.size
    if bbox is not None:
        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)
        cx = int((2 * bbox[0] + bbox[2]) / 2)
        cy = int((2 * bbox[1] + bbox[3]) / 2)
        y1 = max(0, cy - R)
        y2 = min(h, cy + R)
        x1 = max(0, cx - R)
        x2 = min(w, cx + R)
        img = img.crop([x1, y1, x2, y2])
    img = img.resize(image_size, Image.BILINEAR)
    return img

def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):
    filenames = load_filenames(filenames_file_path)
    class_ids = load_class_ids(class_info_file_path)
    bboxes = load_bounding_boxes(cub_dataset_dir)
    all_embeddings = load_embeddings(embeddings_file_path)
    X, y, E = [], [], []
    for idx, fn in enumerate(filenames):
        bbox = bboxes.get(fn, None)
        try:
            img_path = f'{cub_dataset_dir}/images/{fn}.jpg'
            img = get_img(img_path, bbox, image_size)
            emb_stack = all_embeddings[idx, :, :]
            pick = random.randint(0, emb_stack.shape[0] - 1)
            emb = emb_stack[pick, :]
            X.append(np.array(img))
            y.append(class_ids[idx])
            E.append(emb)
        except Exception as e:
            continue
    X = np.array(X)
    y = np.array(y)
    E = np.array(E)
    return X, y, E

def reparam_c(x):
    mean = x[:, :128]
    log_sigma = x[:, 128:]
    std = K.exp(log_sigma)
    eps = K.random_normal(shape=K.shape(std))
    return std * eps + mean

def build_embedding_compressor_model():
    inp = Input(shape=(1024,))
    x = Dense(256)(inp)
    x = ReLU()(x)
    x = Dense(128)(x)
    x = ReLU()(x)
    return Model(inp, x)

def build_stage1_generator():
    txt = Input(shape=(1024,))
    z = Input(shape=(100,))
    h = Dense(256)(txt)
    h = LeakyReLU(0.2)(h)
    mean_logsigma = Dense(256)(h)
    c = Lambda(reparam_c)(mean_logsigma)
    g_in = Concatenate(axis=1)([c, z])
    x = Dense(4*4*512, use_bias=False)(g_in)
    x = ReLU()(x)
    x = Reshape((4,4,512))(x)
    x = Conv2DTranspose(256, kernel_size=4, strides=2, padding="same", use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv2DTranspose(128, kernel_size=4, strides=2, padding="same", use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv2DTranspose(64, kernel_size=4, strides=2, padding="same", use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv2DTranspose(32, kernel_size=4, strides=2, padding="same", use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)
    x = Conv2D(3, kernel_size=3, strides=1, padding="same", use_bias=False)(x)
    x = Activation('tanh')(x)
    return Model([txt, z], [x, mean_logsigma])

def build_stage1_discriminator():
    img = Input(shape=(64,64,3))
    cond = Input(shape=(4,4,128))
    x = Conv2D(64, 4, strides=2, padding='same', use_bias=False)(img)
    x = LeakyReLU(0.2)(x)
    x = Conv2D(128, 4, strides=2, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.2)(x)
    x = Conv2D(256, 4, strides=2, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.2)(x)
    x = Conv2D(512, 4, strides=2, padding='same', use_bias=False)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.2)(x)
    m = Concatenate(axis=-1)([x, cond])
    x2 = Conv2D(512, 1, strides=1, padding="same")(m)
    x2 = BatchNormalization()(x2)
    x2 = LeakyReLU(0.2)(x2)
    x2 = Flatten()(x2)
    x2 = Dense(1)(x2)
    x2 = Activation('sigmoid')(x2)
    return Model([img, cond], x2)

def build_adversarial_model(gen_model, dis_model):
    txt = Input(shape=(1024,))
    z = Input(shape=(100,))
    cond = Input(shape=(4,4,128))
    x, mean_logsigma = gen_model([txt, z])
    dis_model.trainable = False
    valid = dis_model([x, cond])
    return Model([txt, z, cond], [valid, mean_logsigma])

def KL_loss(y_true, y_pred):
    mean = y_pred[:, :128]
    logsigma = y_pred[:, 128:]
    loss = -logsigma + 0.5 * (-1.0 + K.exp(2.0 * logsigma) + K.square(mean))
    return K.mean(loss)

def gen_adv_loss(y_true, y_pred):
    return tf.keras.losses.binary_crossentropy(y_true, y_pred)

def save_rgb_img(img, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    fig = plt.figure()
    ax = fig.add_subplot(1,1,1)
    ax.imshow((img + 1.0) * 0.5)
    ax.axis("off")
    plt.savefig(path, bbox_inches='tight', pad_inches=0)
    plt.close()

def main():
    data_dir = "./birds"
    train_dir = data_dir + "/train"
    test_dir = data_dir + "/test"
    image_size = (64,64)
    batch_size = 64
    z_dim = 100
    epochs = 1000
    condition_dim = 128
    embeddings_file_path_train = train_dir + "/char-CNN-RNN-embeddings.pickle"
    embeddings_file_path_test = test_dir + "/char-CNN-RNN-embeddings.pickle"
    filenames_file_path_train = train_dir + "/filenames.pickle"
    filenames_file_path_test = test_dir + "/filenames.pickle"
    class_info_file_path_train = train_dir + "/class_info.pickle"
    class_info_file_path_test = test_dir + "/class_info.pickle"
    cub_dataset_dir = "./CUB_200_2011"
    dis_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)
    gen_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999)
    X_train, y_train, E_train = load_dataset(filenames_file_path_train, class_info_file_path_train, cub_dataset_dir, embeddings_file_path_train, image_size)
    X_test, y_test, E_test = load_dataset(filenames_file_path_test, class_info_file_path_test, cub_dataset_dir, embeddings_file_path_test, image_size)
    stage1_dis = build_stage1_discriminator()
    stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)
    stage1_gen = build_stage1_generator()
    stage1_gen.compile(loss="mse", optimizer=gen_optimizer)
    embed_comp = build_embedding_compressor_model()
    embed_comp.compile(loss="mse", optimizer="adam")
    adv_model = build_adversarial_model(stage1_gen, stage1_dis)
    adv_model.compile(loss=[gen_adv_loss, KL_loss], loss_weights=[1.0, 2.0], optimizer=gen_optimizer)
    real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9
    fake_labels = np.zeros((batch_size, 1), dtype=np.float32) + 0.1
    num_batches = int(X_train.shape[0] / batch_size)
    for epoch in range(epochs):
        gen_losses, dis_losses = [], []
        for b in range(num_batches):
            z = np.random.normal(0, 1, size=(batch_size, z_dim)).astype(np.float32)
            imgs = X_train[b*batch_size:(b+1)*batch_size].astype(np.float32)
            embs = E_train[b*batch_size:(b+1)*batch_size].astype(np.float32)
            imgs = (imgs - 127.5) / 127.5
            fake_images, _ = stage1_gen.predict([embs, z], verbose=0)
            comp = embed_comp.predict_on_batch(embs)
            comp = np.reshape(comp, (-1,1,1,condition_dim))
            comp = np.tile(comp, (1,4,4,1))
            d_real = stage1_dis.train_on_batch([imgs, comp], real_labels)
            d_fake = stage1_dis.train_on_batch([fake_images, comp], fake_labels)
            d_wrong = stage1_dis.train_on_batch([imgs[:batch_size-1], comp[1:]], fake_labels[1:])
            d_loss = 0.5 * (d_real + 0.5 * (d_wrong + d_fake))
            y_adv = np.ones((batch_size,1), dtype=np.float32) * 0.9
            y_kl = np.ones((batch_size,256), dtype=np.float32) * 0.9
            g_loss = adv_model.train_on_batch([embs, z, comp], [y_adv, y_kl])
            dis_losses.append(d_loss)
            gen_losses.append(g_loss if np.isscalar(g_loss) else g_loss[0])
        if epoch % 2 == 0 and E_test.shape[0] >= batch_size:
            z2 = np.random.normal(0, 1, size=(batch_size, z_dim)).astype(np.float32)
            embs_t = E_test[:batch_size].astype(np.float32)
            imgs_gen, _ = stage1_gen.predict_on_batch([embs_t, z2])
            for i, img in enumerate(imgs_gen[:10]):
                save_rgb_img(img, f"./results/gen_{epoch}_{i}.png")
    os.makedirs("./weights", exist_ok=True)
    stage1_gen.save_weights("./weights/stage1_gen.h5")
    stage1_dis.save_weights("./weights/stage1_dis.h5")

if __name__ == "__main__":
    os.makedirs("./results", exist_ok=True)
    main()
